{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulletines Cleaning\n",
    "\n",
    "I used this notebook to clean raw data previously scraped containing information from the monthly bulletines published by the Italian Ministry of Justice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic cleaning\n",
    "\n",
    "- Converting numbers into integers (note that the `.` in Italy is being used as a decimal separator)\n",
    "- Removing `Totals` (we'll calculate them when needed)\n",
    "- Fixing empty values to numeric (from NaN to 0)\n",
    "- Converting to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read CSV with thousands separator specified\n",
    "df = pd.read_csv(\"../outputs/raw/bulletines_raw.csv\", thousands=\".\")\n",
    "\n",
    "# Remove rows where \"Regione di detenzione\" is \"Totale\"\n",
    "df = df[df[\"Regione di detenzione\"] != \"Totale\"]\n",
    "\n",
    "# Replace empty strings and similar with NaN\n",
    "df.replace([\"\", \" \", \"NaN\", \"nan\"], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Convert columns to integer type\n",
    "df['Detenuti presenti - stranieri'] = df['Detenuti presenti - stranieri'].astype(int)\n",
    "\n",
    "# Remove dots from numeric strings in the specified column\n",
    "df['Detenuti presenti - totale'] = df['Detenuti presenti - totale'].str.replace(\".\", \"\")\n",
    "\n",
    "# Show a random sample of 5 rows\n",
    "df.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Replace dots in the 'Detenuti presenti - totale' column, then convert to numeric\n",
    "df['Detenuti presenti - totale'] = df['Detenuti presenti - totale'].str.replace(\".\", \"\").astype(float)\n",
    "# Step 2: Fill any remaining NaN values with 0\n",
    "df['Detenuti presenti - totale'].fillna(0, inplace=True)\n",
    "# Step 3: Convert the cleaned column to integers\n",
    "df['Detenuti presenti - totale'] = df['Detenuti presenti - totale'].astype(int)\n",
    "df['Detenuti presenti - donne'] = df['Detenuti presenti - donne'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('Detenuti presenti - stranieri', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Ultimo aggiornamento' column to datetime format\n",
    "df['Ultimo aggiornamento'] = pd.to_datetime(df['Ultimo aggiornamento'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing names\n",
    "\n",
    "A problem we are encountering are the many different names each detention center has been registered with over the years. Here below we use [thefuzz](https://github.com/seatgeek/thefuzz) to do an initial fuzzy matching, and then fix the remaining ones manually. As a reference, we'll use the information we have scraped in a different notebook about all the detention centers currently operating in Italy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Istituto'] = df['Istituto'].str.strip()\n",
    "df['Istituto'] = df['Istituto'].str.replace(r\"\\s*-\", \"\", regex=True)  # Removes any whitespace followed by a dash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df['Istituto'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thefuzz import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard names\n",
    "df_standard_names = pd.read_csv('../outputs/clean/institutes_info.csv')\n",
    "standard_names = df_standard_names['nome_istituto'].tolist()\n",
    "standard_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df\n",
    "df_copy.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_name(name):\n",
    "    match, score = process.extractOne(name, standard_names)\n",
    "    return match if score >= 90 else name  # Adjust score threshold as needed\n",
    "# Apply fuzzy matching to standardize names\n",
    "df_copy['Istituto'] = df_copy['Istituto'].apply(standardize_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df_copy['Istituto'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the names that did not match are uppercase, we can identify them easily and proceed with a mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df_copy[df_copy['Istituto'].str.isupper()]['Istituto'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "institute_mapping = {\n",
    "    'BRESCIA \"N. FISCHIONE\" CANTON MONBELLO': 'Brescia Canton Monbello',\n",
    "    'BRESCIA \"NERIO FISCHIONE\" CANTON MONBELLO': 'Brescia Canton Monbello',\n",
    "    'CAGLIARI \"E.SCALAS\"': 'Cagliari Uta',\n",
    "    'CAGLIARI \"ETTORE SCALAS\"': 'Cagliari Uta',\n",
    "    'CAMERINO': 'Camerino',\n",
    "    'CIVITAVECCHIA \"N.C.\"': 'Civitavecchia Nuovo Complesso',\n",
    "    \"FORLI'\": 'Forl√¨',\n",
    "    'MILANO \"F. DI CATALDO\" SAN VITTORE': 'Milano San Vittore',\n",
    "    'MILANO \"FRANCESCO DI CATALDO\" SAN VITTORE': 'Milano San Vittore',\n",
    "    'NAPOLI \"G. SALVIA\" POGGIOREALE': 'Napoli Poggioreale',\n",
    "    'NAPOLI \"GIUSEPPE SALVIA\" POGGIOREALE': 'Napoli Poggioreale',\n",
    "    'NAPOLI \"P. MANDATO\" SECONDIGLIANO': 'Napoli Secondigliano',\n",
    "    'NAPOLI \"PASQUALE MANDATO\" SECONDIGLIANO': 'Napoli Secondigliano',\n",
    "    'PALERMO \"A. LORUSSO\" PAGLIARELLI': 'Palermo Pagliarelli',\n",
    "    'PALERMO \"ANTONIO LORUSSO\" PAGLIARELLI': 'Palermo Pagliarelli',\n",
    "    'PALERMO \"C. DI BONA\" UCCIARDONE': 'Palermo Ucciardone',\n",
    "    'PALERMO \"CALOGERO DI BONA\" UCCIARDONE': 'Palermo Ucciardone',\n",
    "    'ROMA \"G. STEFANINI\" REBIBBIA FEMMINILE': 'Roma Rebibbia Femminile',\n",
    "    'ROMA \"GERMANA STEFANINI\" REBIBBIA FEMMINILE': 'Roma Rebibbia Femminile',\n",
    "    'ROMA \"R. CINOTTI\" REBIBBIA N.C.1': 'Roma Rebibbia',\n",
    "    'ROMA \"RAFFAELE CINOTTI\" REBIBBIA N.C.1': 'Roma Rebibbia',\n",
    "    'ROMA \"REBIBBIA TERZA CASA\"': 'Roma Rebibbia III Casa',\n",
    "    'SAN REMO \"N.C.\"': 'Sanremo',\n",
    "}\n",
    "\n",
    "df_copy['Istituto'] = df_copy['Istituto'].replace(institute_mapping)\n",
    "\n",
    "# Check the updated unique values\n",
    "df_copy['Istituto'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove duplicate data from Dec 2021\n",
    "# df_copy = df_copy[df_copy['ID'] != 'SST360932']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.to_csv('../outputs/clean/bulletines.csv', index=False, encoding=\"UTF-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
